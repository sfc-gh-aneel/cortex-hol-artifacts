{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9923d8-945b-4b4b-8d37-3a48807cafa3",
   "metadata": {
    "collapsed": false,
    "name": "MD_intro"
   },
   "source": [
    "# 🧠 Seclock Document Q&A – Multimodal Document Pipeline (Streamlit UI)\n",
    "\n",
    "This script powers an interactive Streamlit app that answers technical questions about Seclock’s door hardware documents using **multimodal AI**—combining vector search, LLM reasoning, and image validation via Snowflake Cortex.\n",
    "\n",
    "## 🔧 High-Level Features\n",
    "\n",
    "- 📥 **Document Ingestion & Processing**\n",
    "  - Splits PDFs into per-page images and text using `parse_document()`.\n",
    "  - Stores images in a Snowflake stage and text/metadata in structured tables.\n",
    "  - Generates image embeddings using `embed_image_1024`.\n",
    "---\n",
    "- 🔍 **Semantic Search & Retrieval**\n",
    "  - Converts user questions into temporary query images to leverage image embeddings.\n",
    "  - Embeds the image and performs vector search via Cortex Search Service.\n",
    "  - Retrieves top matching enriched chunks (text + metadata + image reference).\n",
    "---\n",
    "- 🧠 **LLM-Based Text Answering**\n",
    "  - Feeds retrieved context into Claude (`claude-3-7-sonnet`) to generate:\n",
    "    - Direct answers\n",
    "    - Confidence scores\n",
    "    - Justifications\n",
    "    - Markdown-linked citations (`[Document - page X](presigned_url)`)\n",
    "---\n",
    "- 🖼️ **Image-Based Reasoning**\n",
    "  - Identifies cited pages from the text answer and filters matching images.\n",
    "  - Submits images asynchronously to Cortex for answer validation.\n",
    "  - Uses image metadata and visual context to extract direct answers or critiques.\n",
    "---\n",
    "- 🧪 **Answer Synthesis**\n",
    "  - Combines text and image-based answers into a final, human-readable response.\n",
    "  - Rewrites for clarity, accuracy, and directness.\n",
    "  - Prioritizes newer or more reliable sources and flags conflicting evidence.\n",
    "  - Provides full citation trail with links to specific document pages.\n",
    "---\n",
    "- 🔗 **Embedding & Retrieval Enrichment**\n",
    "  - Merges document metadata, summaries, page-level chunks, and vectors into a retrieval-optimized format.\n",
    "  - Allows precise filtering and future expansion (e.g., by product line or brand).\n",
    "---\n",
    "- 💬 **Streamlit Chat UI**\n",
    "  - Provides an interactive chatbot interface with step-by-step progress feedback.\n",
    "  - Includes expandable debug sections for:\n",
    "    - Source documents used\n",
    "    - Text answer reasoning\n",
    "    - Image-based critiques\n",
    "    - LLM prompt previews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "PY_imports"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import hashlib\n",
    "from difflib import SequenceMatcher\n",
    "import tempfile\n",
    "from textwrap import dedent\n",
    "import streamlit as st\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from contextlib import contextmanager\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from typing import Tuple\n",
    "import snowflake.snowpark.session as session\n",
    "import pdfplumber\n",
    "import PyPDF2\n",
    "import streamlit as st\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.core import Root\n",
    "from snowflake.cortex import complete, CompleteOptions\n",
    "sp_session = get_active_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc14c85-301e-4f5a-b7f7-059355aa2230",
   "metadata": {
    "collapsed": false,
    "name": "MD_pdf_to_image"
   },
   "source": [
    "## 📄 PDF Preprocessing Pipeline for Document Analysis\n",
    "\n",
    "Preprocesses PDFs stored in a Snowflake stage, preparing them for downstream AI document analysis. It lists all PDF files in a specified input stage, downloads each file temporarily, and performs two key operations: \n",
    "\n",
    "1. Splitting the PDF into individual pages and uploading each as a separate PDF file\n",
    "2. Converting each page into a high-resolution image, optionally scaled to a maximum dimension, and uploading the images back to a specified output stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad96295-d4e4-43d7-8ab5-62f685fef26f",
   "metadata": {
    "language": "python",
    "name": "PY_pdf_to_image"
   },
   "outputs": [],
   "source": [
    "def print_info(msg: str) -> None:\n",
    "    \"\"\"Print info message\"\"\"\n",
    "    print(f\"INFO: {msg}\", file=sys.stderr)\n",
    "\n",
    "\n",
    "def print_error(msg: str) -> None:\n",
    "    \"\"\"Print error message\"\"\"\n",
    "    print(f\"ERROR: {msg}\", file=sys.stderr)\n",
    "    if hasattr(st, \"error\"):\n",
    "        st.error(msg)\n",
    "\n",
    "\n",
    "def print_warning(msg: str) -> None:\n",
    "    \"\"\"Print warning message\"\"\"\n",
    "    print(f\"WARNING: {msg}\", file=sys.stderr)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    input_stage: str = \"@UTILS.AI.STOCK_IKB_DOCUMENTS/pre_processed/\"\n",
    "    output_stage: str = (\n",
    "        \"@UTILS.AI.STOCK_IKB_DOCUMENTS/\"  # Base output stage without subdirectories\n",
    "    )\n",
    "    input_path: str = \"pre_processed\"\n",
    "    output_pdf_path: str = \"paged_pdf\"\n",
    "    output_image_path: str = \"paged_image\"\n",
    "    allowed_extensions: List[str] = None\n",
    "    max_dimension: int = 1500  # Maximum dimension in pixels before scaling\n",
    "    dpi: int = 300  # Default DPI for image conversion\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.allowed_extensions is None:\n",
    "            self.allowed_extensions = [\".pdf\"]\n",
    "\n",
    "\n",
    "class PDFProcessingError(Exception):\n",
    "    \"\"\"Base exception for PDF processing errors\"\"\"\n",
    "\n",
    "\n",
    "class FileDownloadError(PDFProcessingError):\n",
    "    \"\"\"Raised when file download fails\"\"\"\n",
    "\n",
    "\n",
    "class PDFConversionError(PDFProcessingError):\n",
    "    \"\"\"Raised when PDF conversion fails\"\"\"\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def managed_temp_file(suffix: str = None) -> str:\n",
    "    \"\"\"Context manager for temporary file handling\"\"\"\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)\n",
    "    try:\n",
    "        yield temp_file.name\n",
    "    finally:\n",
    "        # Don't delete the file immediately, let the caller handle cleanup\n",
    "        pass\n",
    "\n",
    "\n",
    "def cleanup_temp_file(file_path: str) -> None:\n",
    "    \"\"\"Clean up a temporary file\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            os.unlink(file_path)\n",
    "    except OSError as e:\n",
    "        print_warning(f\"Failed to delete temporary file {file_path}: {e}\")\n",
    "\n",
    "\n",
    "def list_pdf_files(session: session.Session, config: Config) -> List[dict]:\n",
    "    \"\"\"List all PDF files in the source stage\"\"\"\n",
    "    try:\n",
    "        # Use LIST command instead of DIRECTORY function\n",
    "        query = f\"\"\"\n",
    "        LIST {config.input_stage}\n",
    "        \"\"\"\n",
    "\n",
    "        file_list = session.sql(query).collect()\n",
    "\n",
    "        # Filter for PDF files\n",
    "        pdf_files = []\n",
    "        for file_info in file_list:\n",
    "            full_path = file_info[\"name\"]\n",
    "            # Extract just the filename from the full path\n",
    "            file_name = os.path.basename(full_path)\n",
    "\n",
    "            if any(\n",
    "                file_name.lower().endswith(ext) for ext in config.allowed_extensions\n",
    "            ):\n",
    "                pdf_files.append(\n",
    "                    {\n",
    "                        \"RELATIVE_PATH\": file_name,  # Use just the filename\n",
    "                        \"FULL_STAGE_PATH\": full_path,  # Use full path for download\n",
    "                        \"SIZE\": file_info[\"size\"] if \"size\" in file_info else 0,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        print_info(f\"Found {len(pdf_files)} PDF files in the stage\")\n",
    "        return pdf_files\n",
    "    except Exception as e:\n",
    "        print_error(f\"Failed to list files: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def download_file_from_stage(\n",
    "    session: session.Session, file_path: str, config: Config\n",
    ") -> str:\n",
    "    \"\"\"Download a file from stage using session.file.get\"\"\"\n",
    "    # Create a temporary directory\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    try:\n",
    "        # Ensure there are no double slashes in the path\n",
    "        stage_path = f\"{config.input_stage.rstrip('/')}/{file_path.lstrip('/')}\"\n",
    "\n",
    "        # Get the file from stage\n",
    "        get_result = session.file.get(stage_path, temp_dir)\n",
    "        if not get_result or get_result[0].status != \"DOWNLOADED\":\n",
    "            raise FileDownloadError(f\"Failed to download file: {file_path}\")\n",
    "\n",
    "        # Construct the local path where the file was downloaded\n",
    "        local_path = os.path.join(temp_dir, os.path.basename(file_path))\n",
    "        if not os.path.exists(local_path):\n",
    "            raise FileDownloadError(f\"Downloaded file not found at: {local_path}\")\n",
    "\n",
    "        return local_path\n",
    "    except Exception as e:\n",
    "        print_error(f\"Error downloading {file_path}: {e}\")\n",
    "        # Clean up the temporary directory\n",
    "        try:\n",
    "            import shutil\n",
    "\n",
    "            shutil.rmtree(temp_dir)\n",
    "        except Exception as cleanup_error:\n",
    "            print_warning(f\"Failed to clean up temporary directory: {cleanup_error}\")\n",
    "        raise FileDownloadError(f\"Failed to download file: {e}\")\n",
    "\n",
    "\n",
    "def upload_file_to_stage(\n",
    "    session: session.Session, file_path: str, output_path: str, config: Config\n",
    ") -> str:\n",
    "    \"\"\"Upload file to the output stage\"\"\"\n",
    "    try:\n",
    "        # Get the directory and filename from the output path\n",
    "        output_dir = os.path.dirname(output_path)\n",
    "        base_name = os.path.basename(output_path)\n",
    "\n",
    "        # Create the full stage path with subdirectory\n",
    "        stage_path = f\"{config.output_stage.rstrip('/')}/{output_dir.lstrip('/')}\"\n",
    "\n",
    "        # Read the content of the original file\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            file_content = f.read()\n",
    "\n",
    "        # Create a new file with the correct name\n",
    "        temp_dir = tempfile.gettempdir()\n",
    "        temp_file_path = os.path.join(temp_dir, base_name)\n",
    "\n",
    "        # Write the content to the new file\n",
    "        with open(temp_file_path, \"wb\") as f:\n",
    "            f.write(file_content)\n",
    "\n",
    "        # Upload the file using session.file.put with compression disabled\n",
    "        put_result = session.file.put(\n",
    "            temp_file_path, stage_path, auto_compress=False, overwrite=True\n",
    "        )\n",
    "\n",
    "        # Check upload status\n",
    "        if not put_result or len(put_result) == 0:\n",
    "            raise Exception(f\"Failed to upload file: {base_name}\")\n",
    "\n",
    "        if put_result[0].status not in [\"UPLOADED\", \"SKIPPED\"]:\n",
    "            raise Exception(f\"Upload failed with status: {put_result[0].status}\")\n",
    "\n",
    "        # Clean up the temporary file\n",
    "        if os.path.exists(temp_file_path):\n",
    "            os.remove(temp_file_path)\n",
    "\n",
    "        return f\"Successfully uploaded {base_name} to {stage_path}\"\n",
    "    except Exception as e:\n",
    "        print_error(f\"Error uploading file: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def process_pdf_files(config: Config) -> None:\n",
    "    \"\"\"Main process to orchestrate the PDF splitting\"\"\"\n",
    "    try:\n",
    "        session = get_active_session()\n",
    "        pdf_files = list_pdf_files(session, config)\n",
    "\n",
    "        for file_info in pdf_files:\n",
    "            file_path = file_info[\"RELATIVE_PATH\"]\n",
    "            print_info(f\"Processing: {file_path}\")\n",
    "\n",
    "            try:\n",
    "                # Download the PDF file\n",
    "                local_pdf_path = download_file_from_stage(session, file_path, config)\n",
    "\n",
    "                # Get base filename without extension\n",
    "                base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "                # Extract individual PDF pages\n",
    "                with open(local_pdf_path, \"rb\") as file:\n",
    "                    pdf_reader = PyPDF2.PdfReader(file)\n",
    "                    num_pages = len(pdf_reader.pages)\n",
    "                    print_info(f\"Converting PDF to {num_pages} pages of PDFs\")\n",
    "\n",
    "                    for i in range(num_pages):\n",
    "                        page_num = i + 1\n",
    "                        s3_pdf_output_path = (\n",
    "                            f\"{config.output_pdf_path}/{base_name}_page_{page_num}.pdf\"\n",
    "                        )\n",
    "                        pdf_writer = PyPDF2.PdfWriter()\n",
    "                        pdf_writer.add_page(pdf_reader.pages[i])\n",
    "                        temp_file = tempfile.NamedTemporaryFile(\n",
    "                            delete=False, suffix=\".pdf\"\n",
    "                        )\n",
    "                        local_pdf_tmp_file_name = temp_file.name\n",
    "                        with open(local_pdf_tmp_file_name, \"wb\") as output_file:\n",
    "                            pdf_writer.write(output_file)\n",
    "                        \n",
    "                        upload_file_to_stage(\n",
    "                            session, local_pdf_tmp_file_name, s3_pdf_output_path, config\n",
    "                        )\n",
    "                        cleanup_temp_file(local_pdf_tmp_file_name)\n",
    "                            \n",
    "                # Convert PDF to images                \n",
    "                with pdfplumber.open(local_pdf_path) as pdf:\n",
    "                    print_info(f\"Converting PDF to {len(pdf.pages)} images\")\n",
    "                    for i, page in enumerate(pdf.pages):\n",
    "                        page_num = i + 1\n",
    "                        # Get page dimensions\n",
    "                        width = page.width\n",
    "                        height = page.height\n",
    "\n",
    "                        # Determine if scaling is needed\n",
    "                        max_dim = max(width, height)\n",
    "                        if max_dim > config.max_dimension:\n",
    "                            # Calculate scale factor to fit within max_dimension\n",
    "                            scale_factor = config.max_dimension / max_dim\n",
    "                            width = int(width * scale_factor)\n",
    "                            height = int(height * scale_factor)\n",
    "\n",
    "                        img = page.to_image(resolution=config.dpi)\n",
    "                        temp_file = tempfile.NamedTemporaryFile(\n",
    "                            delete=False, suffix=\".png\"\n",
    "                        )\n",
    "                        local_image_tmp_file_name = temp_file.name\n",
    "                        img.save(local_image_tmp_file_name)\n",
    "\n",
    "                        s3_image_output_path = (\n",
    "                            f\"{config.output_image_path}/{base_name}_page_{page_num}.png\"\n",
    "                        )\n",
    "                        \n",
    "                        upload_file_to_stage(\n",
    "                            session, local_image_tmp_file_name, s3_image_output_path, config\n",
    "                        )\n",
    "                        cleanup_temp_file(local_image_tmp_file_name)\n",
    "                        \n",
    "                # Clean up the original downloaded file\n",
    "                cleanup_temp_file(local_pdf_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print_error(f\"Error processing {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print_error(f\"Fatal error in process_pdf_files: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710c338-9693-4d20-8459-3eb567595a0a",
   "metadata": {
    "language": "python",
    "name": "PY_run_pdf_to_image"
   },
   "outputs": [],
   "source": [
    "config = Config(dpi=300)\n",
    "process_pdf_files(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ff282e-8bbc-4910-be87-f74345c98a7e",
   "metadata": {
    "collapsed": false,
    "name": "MD_image_preview"
   },
   "source": [
    "## 🔍 Document Image Preview\n",
    "\n",
    "To check everything has been processed as planned, we can look at an image representing a page from the PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb451f8-d784-47fe-be85-0697507bc2b0",
   "metadata": {
    "language": "python",
    "name": "PY_image_preview"
   },
   "outputs": [],
   "source": [
    "image=sp_session.file.get_stream(\n",
    "     f\"@UTILS.AI.STOCK_IKB_DOCUMENTS/paged_image/2025-sargent-price-book_page_16.png\",\n",
    "     decompress=False).read()\n",
    "st.image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7bbcfc-b7b4-4550-b181-ab9df1e37891",
   "metadata": {
    "language": "sql",
    "name": "SQL_use_role"
   },
   "outputs": [],
   "source": [
    "use role utils__ai__owner__s_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd639952-f63d-4534-a7ca-13b5c898dbdd",
   "metadata": {
    "collapsed": false,
    "name": "MD_image_embedding"
   },
   "source": [
    "## 🧠 Batch Image Embedding with Cortex and Snowpark\n",
    "\n",
    "This workflow performs batch image embedding using a Python stored procedure\n",
    "\n",
    "1. **Identify Unprocessed Images**\n",
    "   A temporary table (`limit_directory_table`) is created by listing all image files in the stage (`@utils.ai.stock_ikb_documents/paged_image/`) and filtering out those already embedded in the `output_vector_table`.\n",
    "\n",
    "2. **Assign Row Numbers for Batching**\n",
    "   Each unprocessed image file is assigned a `row_number()` so batches can be defined by row ranges (`start_rn` to `end_rn`).\n",
    "\n",
    "3. **Define Embedding Procedure**\n",
    "   A Python stored procedure `run_image_embedding_batch(start_rn, end_rn)` is created. It:\n",
    "\n",
    "   * Reads a batch of image files from the temporary table.\n",
    "   * Extracts file and metadata (e.g. file name, page number).\n",
    "   * Computes an image embedding using `snowflake.cortex.embed_image_1024` with the `voyage-multimodal-3` model.\n",
    "   * Saves the embeddings to `output_vector_table`.\n",
    "\n",
    "4. **Queue Up Batch Jobs**\n",
    "   The total number of batches is calculated, and a list of SQL `CALL` statements is built, one per batch.\n",
    "\n",
    "5. **Run Jobs Concurrently**\n",
    "   A loop manages job execution with up to 5 concurrent asynchronous jobs at a time. Each job is submitted using `.collect_nowait()` and polled until it completes.\n",
    "\n",
    "6. **Monitor and Retry**\n",
    "   Each batch is logged upon completion or failure, and the loop continues until all batches are processed.\n",
    "\n",
    "This setup allows high-throughput embedding of images inside Snowflake, using Cortex's multimodal capabilities with minimal manual orchestration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a214a51-92d6-42b5-854f-a7da48b04402",
   "metadata": {
    "language": "sql",
    "name": "SQL_image_embedding_sproc"
   },
   "outputs": [],
   "source": [
    "create or replace procedure run_image_embedding_batch(start_rn int, end_rn int)\n",
    "returns string\n",
    "language python\n",
    "runtime_version = 3.9\n",
    "packages = ('snowflake-snowpark-python')\n",
    "handler = 'embed_handler'\n",
    "AS\n",
    "$$\n",
    "def embed_handler(session, start_rn, end_rn):\n",
    "    df = session.sql(f'''\n",
    "        select\n",
    "            concat('paged_image/', split_part(relative_path, '/', -1)) as file_name,\n",
    "            regexp_substr(file_name, 'paged_image/(.*)\\\\.png$', 1, 1, 'e', 1) as paged_file_name,\n",
    "            split_part(paged_file_name, '_page_', 0) as original_file_name,\n",
    "            split_part(paged_file_name, '_page_', 2)::int as page_number,\n",
    "            '@utils.ai.stock_ikb_documents' as stage_prefix,\n",
    "            to_file(file_url)  as image_file,\n",
    "            snowflake.cortex.embed_image_1024(\n",
    "                'voyage-multimodal-3', \n",
    "                '@utils.ai.stock_ikb_documents', \n",
    "                concat('paged_image/', split_part(relative_path, '/', -1))\n",
    "            ) as image_vector\n",
    "        from limit_directory_table\n",
    "        where rn between {start_rn} and {end_rn}\n",
    "    ''')\n",
    "    df.write.save_as_table(\"OUTPUT_VECTOR_TABLE\", mode=\"append\")\n",
    "    return f\"Embedded and saved RN {start_rn} to {end_rn}\"\n",
    "$$;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f45bd12-76ab-4051-b716-6bb080b97ec5",
   "metadata": {
    "language": "python",
    "name": "PY_image_embedding"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "MAX_CONCURRENT = 5\n",
    "\n",
    "# 1. Create LIMIT_DIRECTORY_TABLE if not exists\n",
    "sp_session.sql(\"\"\"\n",
    "    create or replace temporary table limit_directory_table as\n",
    "    select\n",
    "        *,\n",
    "        row_number() over (order by relative_path) as rn\n",
    "    from\n",
    "        directory(@utils.ai.stock_ikb_documents)\n",
    "    where\n",
    "        relative_path like '%paged_image/%'\n",
    "        and\n",
    "        relative_path not in (\n",
    "            select file_name from output_vector_table\n",
    "        )\n",
    "\"\"\").collect()\n",
    "\n",
    "# 2. Get total batches\n",
    "max_rn = sp_session.sql(\"select max(rn) AS max_rn from limit_directory_table\").collect()[0][\"MAX_RN\"]\n",
    "total_batches = (max_rn + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "# 3. Prepare all batch configs\n",
    "batch_queue = []\n",
    "for i in range(total_batches):\n",
    "    start_rn = i * BATCH_SIZE + 1\n",
    "    end_rn = min((i + 1) * BATCH_SIZE, max_rn)\n",
    "    label = f\"Batch {i+1}: RN {start_rn}-{end_rn}\"\n",
    "    sql = f\"call run_image_embedding_batch({start_rn}, {end_rn})\"\n",
    "    batch_queue.append((sql, label))\n",
    "\n",
    "# 4. Loop with max 5 concurrent jobs\n",
    "active_jobs = []\n",
    "\n",
    "while batch_queue or active_jobs:\n",
    "    # Launch jobs if we have capacity\n",
    "    while batch_queue and len(active_jobs) < MAX_CONCURRENT:\n",
    "        sql, label = batch_queue.pop(0)\n",
    "        print(f\"🚀 Submitting async job for {label}\")\n",
    "        try:\n",
    "            job = sp_session.sql(sql).collect_nowait()\n",
    "            active_jobs.append((job, label))\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to submit {label}: {e}\")\n",
    "\n",
    "    # Poll active jobs\n",
    "    for job, label in active_jobs.copy():\n",
    "        if job.is_done():\n",
    "            try:\n",
    "                result = job.result()\n",
    "                print(f\"✅ {label} completed: {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ {label} failed: {e}\")\n",
    "            active_jobs.remove((job, label))\n",
    "\n",
    "    if active_jobs:\n",
    "        time.sleep(15)\n",
    "\n",
    "print(\"🎉 All batches processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9ead8",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd82d8-665b-4715-8d4d-791776f593a2",
   "metadata": {
    "collapsed": false,
    "name": "MD_ocr"
   },
   "source": [
    "## 🔖 Extract Text from PDF Pages\n",
    "\n",
    "This SQL script creates a table (`pdf_pages`) that extracts and stores parsed text content from individual PDF pages:\n",
    "\n",
    "1. **Filter Input Files**\n",
    "   It queries the stage `@utils.ai.stock_ikb_documents` and filters files whose path matches the pattern `%paged_pdf/%`, meaning individual page PDFs from previously split documents.\n",
    "\n",
    "2. **Extract File Metadata**\n",
    "   For each PDF file:\n",
    "\n",
    "   * `file_name` is constructed by prefixing the relative path with `paged_pdf/`.\n",
    "   * `paged_file_name` extracts just the PDF filename using regex.\n",
    "   * `original_file_name` removes the `_page_X` suffix to get the base document name.\n",
    "   * `page_number` is parsed from the filename to track the page.\n",
    "\n",
    "3. **Generate File References**\n",
    "   The `to_file(file_url)` function creates a file object for use in Cortex functions.\n",
    "\n",
    "4. **Parse PDF Content with Cortex**\n",
    "   The `snowflake.cortex.parse_document` function is called on each page to extract its text layout. The result is cast to a string, then parsed as JSON and stored in the `pdf_text` column.\n",
    "\n",
    "5. **Output the Resulting Table**\n",
    "   The final table `pdf_pages` includes:\n",
    "\n",
    "   * File path and name metadata\n",
    "   * Page number\n",
    "   * File reference\n",
    "   * Structured PDF content parsed by Cortex\n",
    "\n",
    "This process enables structured, searchable access to individual page-level text from large documents using Cortex's layout-aware parsing engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e904c",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cc83a2-d562-4a25-b194-05a10e451563",
   "metadata": {
    "language": "sql",
    "name": "SQL_ocr"
   },
   "outputs": [],
   "source": [
    "create or replace table pdf_pages as\n",
    "select\n",
    "    concat('paged_pdf/', split_part(relative_path, '/', -1)) as file_name,\n",
    "    regexp_substr(file_name, 'paged_pdf/(.*)\\\\.pdf$', 1, 1, 'e', 1) as paged_file_name,\n",
    "    split_part(paged_file_name, '_page_', 0) as original_file_name,\n",
    "    split_part(paged_file_name, '_page_', 2)::int as page_number,\n",
    "    '@UTILS.AI.STOCK_IKB_DOCUMENTS' as stage_prefix,\n",
    "    to_file(file_url) as pdf_file,\n",
    "    parse_json(\n",
    "        to_varchar(\n",
    "            snowflake.cortex.parse_document(\n",
    "                '@UTILS.AI.STOCK_IKB_DOCUMENTS',\n",
    "                file_name,\n",
    "                {'mode': 'LAYOUT'}\n",
    "            )\n",
    "        )\n",
    "    ):content as pdf_text\n",
    "from\n",
    "    directory(@utils.ai.stock_ikb_documents)\n",
    "where\n",
    "    relative_path like '%paged_pdf/%'\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae7050-8372-48d3-a4b8-a38b06ce306a",
   "metadata": {
    "collapsed": false,
    "name": "MD_metadata_chunking"
   },
   "source": [
    "## 📖 Enriching PDF Pages with Metadata and Text Chunks for Semantic Search\n",
    "\n",
    "This SQL pipeline creates a comprehensive table (`utils.ai.pdf_images_joined`) that combines page-level text, image embeddings, structured metadata, and semantically formatted chunks optimized for multimodal document retrieval using Snowflake Cortex.\n",
    "\n",
    "### ✅ Steps:\n",
    "\n",
    "1. **🖇️ Join PDF Pages with Image Embeddings**\n",
    "\n",
    "   * Merges parsed PDF page data from `pdf_pages` with vector embeddings from `output_vector_table` via `paged_file_name`.\n",
    "---\n",
    "2. **📄 Select Representative Pages for Metadata**\n",
    "\n",
    "   * Uses `row_number()` to select:\n",
    "\n",
    "     * The **first 10 pages** (for coverage of typical document headers).\n",
    "     * The **last 2 pages** (often contain part indexes or summaries).\n",
    "---\n",
    "3. **🧠 Generate Document-Level Metadata**\n",
    "\n",
    "   * Concatenates the selected pages’ text and feeds it into `ai_complete()` (with `llama4-scout`) to extract:\n",
    "\n",
    "     * `manufacturer`\n",
    "     * `product_line`\n",
    "     * `document_type`\n",
    "     * `effective_date`, `copyright`\n",
    "     * `category`\n",
    "     * `concise_document_summary`\n",
    "---\n",
    "4. **📝 Generate Page-Level Metadata**\n",
    "\n",
    "   * Runs `ai_complete()` (with `llama4-scout`) on each page’s text to extract:\n",
    "\n",
    "     * `page_title`\n",
    "     * `concise_page_summary`\n",
    "---\n",
    "5. **🔗 Join Metadata with Full Page Content**\n",
    "\n",
    "   * Combines document-level and page-level metadata with:\n",
    "\n",
    "     * Raw page text\n",
    "     * Vector embeddings\n",
    "     * File references\n",
    "---\n",
    "6. **✂️ Split Pages into Chunks**\n",
    "\n",
    "   * Uses `cortex.split_text_recursive_character()` to break page text into \\~1800-character, markdown-safe blocks, ensuring semantic cohesion for chunk-level retrieval.\n",
    "---\n",
    "7. **🔍 Enrich Chunks with Visual Context**\n",
    "\n",
    "   * For each chunk:\n",
    "\n",
    "     * Runs `ai_complete()` (with `llama4-maverick`) using the **full page image** and **chunk text**.\n",
    "     * Extracts structured visual context such as:\n",
    "\n",
    "       * **Page region**\n",
    "       * **Table sections or headers**\n",
    "       * **Related elements not captured in the chunk**\n",
    "     * Encourages bullet-point or key-value output grounded in visual layout.\n",
    "---\n",
    "8. **🧱 Build Final Enriched Chunks**\n",
    "\n",
    "   * Combines:\n",
    "\n",
    "     * Source file\n",
    "     * Document and page metadata\n",
    "     * Chunk visual context\n",
    "     * Raw chunk text\n",
    "   * Stores final result in an `enriched_chunk` field optimized for LLM prompts and semantic indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e2d39-332d-4abc-89f5-c132dc885868",
   "metadata": {
    "language": "sql",
    "name": "SQL_metadata_chunking"
   },
   "outputs": [],
   "source": [
    "create or replace table utils.ai.pdf_images_joined as\n",
    "with pdf_images_joined as (\n",
    "    select\n",
    "        pdfs.file_name as pdf_file_name,\n",
    "        images.file_name as image_file_name,\n",
    "        pdfs.original_file_name,\n",
    "        pdfs.page_number,\n",
    "        pdfs.pdf_file,\n",
    "        images.image_file,\n",
    "        images.image_vector,\n",
    "        pdfs.pdf_text,\n",
    "    from\n",
    "        pdf_pages as pdfs\n",
    "    join\n",
    "        output_vector_table as images\n",
    "        on\n",
    "        pdfs.paged_file_name = images.paged_file_name\n",
    "),\n",
    "first_10_pages as (\n",
    "  select\n",
    "    original_file_name,\n",
    "    page_number,\n",
    "    pdf_text,\n",
    "    row_number() over (partition by original_file_name order by page_number) as row_num_start,\n",
    "    row_number() over (partition by original_file_name order by page_number desc) as row_num_end\n",
    "  from\n",
    "    pdf_images_joined\n",
    "),\n",
    "limited_pages as (\n",
    "  select\n",
    "    original_file_name,\n",
    "    page_number,\n",
    "    pdf_text\n",
    "  from \n",
    "    first_10_pages\n",
    "  where \n",
    "    row_num_start <= 10\n",
    "    or\n",
    "    row_num_end <= 2\n",
    "),\n",
    "document_text as (\n",
    "  select\n",
    "    original_file_name,\n",
    "    listagg(pdf_text, '\\n\\n') within group (order by page_number) as full_text\n",
    "  from \n",
    "    limited_pages\n",
    "  group by \n",
    "    original_file_name\n",
    "),\n",
    "get_document_summary as (\n",
    "    select\n",
    "      original_file_name,\n",
    "      full_text,\n",
    "      ai_complete(\n",
    "        model => 'llama4-scout',\n",
    "        prompt => concat(\n",
    "          'You are a document summarization agent processing technical manuals and sales documents ',\n",
    "          'from Seclock, a wholesale distributor of electrical and mechanical door hardware.',\n",
    "          'I am going to provide a document which will be indexed by a retrieval system containing ',\n",
    "          'many similar documents. I want you to provide key information associated with this document ',\n",
    "          'that can help differentiate this document in the index. Follow these instructions:\\n',\n",
    "          '    1. Do not dwell on low level details. Only provide key high level information that a ',\n",
    "          'human might be expected to provide when searching for this doc.\\n\\n',\n",
    "          '    2. Do not use any formatting, just provide keys and values using a colon to separate key ',\n",
    "          'and value. Have each key and value be on a new line.\\n\\n',\n",
    "          '    3. Only extract at most the following information. If you are not confident with pulling ',\n",
    "          'any one of these keys, then do not include that key:\\n',\n",
    "          '    4. Return *nothing* but the key:value pairs.\\n\\n',\n",
    "            array_to_string(\n",
    "                array_construct(\n",
    "                    'manufacturer',\n",
    "                    'product_line',\n",
    "                    'document_type',\n",
    "                    'effective_date',\n",
    "                    'year_of_publication',\n",
    "                    'copyright_year',\n",
    "                    'category',\n",
    "                    'concise_document_summary'\n",
    "                ),\n",
    "                '\\t\\t* '\n",
    "            ),\n",
    "          '\\n\\nDoc starts here:\\n', full_text, '\\nDoc ends here\\n\\n'\n",
    "        ),\n",
    "        model_parameters => {\n",
    "          'temperature': 0.2\n",
    "        }\n",
    "      )::string as document_metadata\n",
    "    from \n",
    "        document_text\n",
    "),\n",
    "describe_pages as (\n",
    "    select\n",
    "        pdf_file_name,\n",
    "        image_file_name,\n",
    "        original_file_name,\n",
    "        page_number,\n",
    "        pdf_file,\n",
    "        image_file,\n",
    "        image_vector,\n",
    "        pdf_text,\n",
    "        ai_complete(\n",
    "          model => 'llama4-scout',\n",
    "          prompt => concat(\n",
    "            'You are a metadata extraction agent working with individual pages from technical manuals and sales documents ',\n",
    "            'from Seclock, a wholesale distributor of electrical and mechanical door hardware.\\n\\n',\n",
    "            'I am going to provide the full text of one page. I want you to extract high-level, distinguishing metadata from this page ',\n",
    "            'that could help index it effectively within a larger document retrieval system.\\n\\n',\n",
    "            'Follow these rules:\\n',\n",
    "            '   1. Do not dwell on low-level or repetitive details.\\n',\n",
    "            '   2. Only provide the following keys as colon-separated key-value pairs, one per line:\\n',\n",
    "              array_to_string(\n",
    "                array_construct(\n",
    "                  'page_title',\n",
    "                  'concise_page_summary'\n",
    "                ),\n",
    "                '\\t\\t* '\n",
    "              ), '\\n',\n",
    "            '   3. If you are not confident about a key, omit it entirely.\\n',\n",
    "            '   4. Return *nothing* but the key:value pairs.\\n\\n',\n",
    "            'Doc starts here:\\n', pdf_text, '\\nDoc ends here\\n\\n'\n",
    "          ),\n",
    "          model_parameters => {\n",
    "            'temperature': 0.1,\n",
    "            'max_tokens': 1024\n",
    "          }\n",
    "        )::string as page_metadata\n",
    "    from\n",
    "        pdf_images_joined\n",
    "),\n",
    "pages_with_metadata as (\n",
    "  select\n",
    "    page.pdf_file_name,\n",
    "    page.image_file_name,\n",
    "    page.original_file_name,\n",
    "    page.page_number,\n",
    "    page.pdf_file,\n",
    "    page.image_file,\n",
    "    page.image_vector,\n",
    "    page.pdf_text,\n",
    "    page.page_metadata,\n",
    "    doc.document_metadata\n",
    "  from\n",
    "    describe_pages page\n",
    "  join\n",
    "    get_document_summary doc\n",
    "    on \n",
    "        page.original_file_name = doc.original_file_name\n",
    "),\n",
    "split_pages_into_chunks as (\n",
    "    select\n",
    "        pdf_file_name,\n",
    "        image_file_name,\n",
    "        original_file_name,\n",
    "        page_number,\n",
    "        image_vector,\n",
    "        pdf_text,\n",
    "        document_metadata,\n",
    "        page_metadata,\n",
    "        ai_complete(\n",
    "            model => 'llama4-maverick',\n",
    "            predicate => concat(\n",
    "                'You are a metadata tagging agent working with scanned document **images** from Seclock,',\n",
    "                'a wholesale distributor of door hardware.\\n\\n',\n",
    "                \n",
    "                'You will be shown:\\n',\n",
    "                '- A **full image** of one page from a technical manual\\n',\n",
    "                '- A **chunk of extracted text** from that page\\n\\n',\n",
    "                \n",
    "                'Your job is to briefly describe what this chunk represents **in context** of the full page image.\\n\\n',\n",
    "                \n",
    "                'If the page is a table, focus on answering these precisely:\\n',\n",
    "                '1. Position: where the chunk appears in the page\\n',\n",
    "                '2. Section Names: section breaks in the table (if they exist)\\n',\n",
    "                '3. Column Headers: e.g. PART No., QTY\\n',\n",
    "\n",
    "                'If the page is not a table, focus on answering these precisely: ',\n",
    "                '1. Position: where the chunk appears in the page\\n',\n",
    "                '2. Relevant Details: precise and brief list of relevant item from the page without which ',\n",
    "                'the chunk cannot be understood (if any)\\n',\n",
    "                \n",
    "                '* Be brief. Use bullet points or key:value format.\\n',\n",
    "                '* Do not repeat the chunk.\\n',\n",
    "                '* Use the page to extract details relevant to the chunk, not just the chunk itself.\\n',\n",
    "                '* Do not speculate beyond the chunk or image.\\n\\n',\n",
    "                \n",
    "                '---\\n\\n',\n",
    "                'Chunk Text:\\n', value::string, '\\n\\n'\n",
    "            ),\n",
    "            file => image_file,\n",
    "          model_parameters => {\n",
    "            'temperature': 0.1,\n",
    "            'max_tokens': 1024\n",
    "          }\n",
    "        )::string as chunk_context,\n",
    "        concat(\n",
    "            '**Source File:** ', original_file_name, '\\n',\n",
    "            '**Document Metadata:** ', coalesce(document_metadata, 'N/A'), '\\n\\n',\n",
    "            '----------------\\n\\n',\n",
    "            '**Page Metadata:** ', coalesce(page_metadata, 'N/A'), '\\n',\n",
    "            '**Page Number:** ', page_number::string, '\\n\\n',\n",
    "            '----------------\\n\\n',\n",
    "            '**Chunk Context:**', chunk_context,\n",
    "             '\\n\\n----------------\\n\\n',\n",
    "            '**Chunk:**\\n\\n', value::string\n",
    "        ) as enriched_chunk\n",
    "    from\n",
    "        pages_with_metadata,\n",
    "    lateral flatten(\n",
    "        input=>snowflake.cortex.split_text_recursive_character(\n",
    "            pdf_text,\n",
    "            'markdown',\n",
    "            1800,\n",
    "            200\n",
    "        )\n",
    "    )\n",
    ")\n",
    "select\n",
    "    pdf_file_name,\n",
    "    image_file_name,\n",
    "    original_file_name,\n",
    "    page_number,\n",
    "    image_vector,\n",
    "    pdf_text,\n",
    "    enriched_chunk\n",
    "from\n",
    "    split_pages_into_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc27bae-b050-45c3-9b60-b6271bc4971a",
   "metadata": {
    "collapsed": false,
    "name": "MD_cortex_search"
   },
   "source": [
    "## 🕵️‍♀️ Build Cortex Search Service\n",
    "\n",
    "We're using the [User-Provided Vector Embeddings in Cortex Search](https://docs.snowflake.com/LIMITEDACCESS/cortex-search/user-provided-vectors) private preview. This allows us to provide precomputed vector embeddings to index and query with Cortex Search, which allows us to use our image embeddings as part of the search service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79e763-5106-42a8-b138-f092391a69de",
   "metadata": {
    "language": "sql",
    "name": "SQL_cortex_search"
   },
   "outputs": [],
   "source": [
    "create or replace cortex search service docs_search_service\n",
    "    text indexes (enriched_chunk)\n",
    "    vector indexes (image_vector)\n",
    "    warehouse = compute_wh\n",
    "    target_lag = '1 day'\n",
    "    as \n",
    "    select \n",
    "        pdf_file_name,\n",
    "        image_file_name,\n",
    "        original_file_name,\n",
    "        page_number,\n",
    "        image_vector,\n",
    "        pdf_text,\n",
    "        enriched_chunk\n",
    "    from \n",
    "        utils.ai.pdf_images_joined\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1630e0-2ed4-493d-869a-0e719b7fa2a7",
   "metadata": {
    "collapsed": false,
    "name": "MD_perform_rag"
   },
   "source": [
    "## 🤖 Multimodal Document Question Answering with Image-Aided Semantic Search\n",
    "\n",
    "This system answers precise technical questions about door hardware products using both **text** and **image-based** reasoning across PDFs. It completes a three-step multimodal process:\n",
    "\n",
    "1. **Text-Based Answering** using enriched document chunks.\n",
    "2. **Image-Based Answer Validation** via OCR page images.\n",
    "3. **Answer Synthesis** to revise and finalize the response.\n",
    "\n",
    "This is done using the following steps:\n",
    "\n",
    "### 1. **Convert User Question into Image Embedding**\n",
    "\n",
    "* `get_text_embedding_via_image()`:\n",
    "\n",
    "  * Renders the user's question as a temporary PNG image.\n",
    "  * Uploads it to a Snowflake stage (`@utils.ai.stock_ikb_documents/queries/`).\n",
    "  * Uses `snowflake.cortex.embed_image_1024()` to generate a **multimodal embedding** via `voyage-multimodal-3`.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Perform Semantic Search with Text + Embedding**\n",
    "\n",
    "* `query_search_service()`:\n",
    "\n",
    "  * Submits both the raw question and the image embedding to a **Cortex search service**.\n",
    "  * Returns the top 50 `ENRICHED_CHUNK`s (text + metadata + image references) relevant to the question.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Rephrase Question for Search Compatibility**\n",
    "\n",
    "* `rephrase_for_search()`:\n",
    "\n",
    "  * Normalizes the user query by trimming and lowercasing it.\n",
    "  * Helps align question formatting with indexed content.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Build Context and Generate Text-Based Answer**\n",
    "\n",
    "* `ai_complete_on_text()`:\n",
    "\n",
    "  * Constructs a markdown-rich prompt from the top retrieved chunks.\n",
    "  * Includes clickable links to the original PDF pages via `presigned_url`.\n",
    "  * Uses `claude-3-7-sonnet` to answer the question directly and include:\n",
    "\n",
    "    * A clear **direct answer**,\n",
    "    * A **confidence score** (0–1),\n",
    "    * A short **justification**, and\n",
    "    * Properly formatted **CITED SOURCES**:\n",
    "      [`Document Name - page X`](presigned_url)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Deduplicate and Filter Pages for Image Critique**\n",
    "\n",
    "* Duplicates are removed based on `(PDF_FILE_NAME, IMAGE_FILE_NAME)` pairs.\n",
    "* `extract_cited_docs_and_pages()` ensures only **relevant document pages** are processed.\n",
    "* `extract_page_number()` helps match images to cited pages.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Run Image-Based Validations (Async)**\n",
    "\n",
    "* `ai_complete_on_image_async()`:\n",
    "\n",
    "  * Submits each matched image to `claude-3-7-sonnet` via `ai_complete()` using:\n",
    "\n",
    "    * Document metadata\n",
    "    * Page number\n",
    "    * The original text answer for critique\n",
    "  * Prompt instructs the model to confirm or revise the answer, ensuring it's grounded in the visual page content.\n",
    "\n",
    "* `resolve_async_job()`:\n",
    "\n",
    "  * Polls the result and extracts fields like:\n",
    "\n",
    "    * `RESULT`, `PAGE_NUMBER`, `IMAGE_FILE_NAME`, `PRESIGNED_URL`.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Filter Image-Based Answers by Confidence**\n",
    "\n",
    "* `filter_by_confidence()`:\n",
    "\n",
    "  * Retains only image completions with `CONFIDENCE >= 0.5`.\n",
    "  * Helps ensure only high-quality critiques contribute to the final answer.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **Synthesize the Final Answer for the User**\n",
    "\n",
    "* `synthesise_all_answers()`:\n",
    "\n",
    "  * Merges text and image critiques into a unified prompt.\n",
    "  * Final LLM prompt includes:\n",
    "\n",
    "    * Original text result\n",
    "    * All image critiques (linked to page images)\n",
    "  * The LLM is instructed to:\n",
    "\n",
    "    * Revise or reaffirm the answer\n",
    "    * Rephrase for user clarity (customer-facing tone)\n",
    "    * Exclude technical fields like `CONFIDENCE` or `JUSTIFICATION`\n",
    "    * Append a **\"Cited Sources\"** section with markdown hyperlinks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a442c-1d03-4045-8314-570caf933df2",
   "metadata": {
    "language": "python",
    "name": "PY_perform_rag"
   },
   "outputs": [],
   "source": [
    "def query_search_service(session, my_service, query_text):\n",
    "    query_embedding = get_text_embedding_via_image(session, query_text)\n",
    "    resp = my_service.search(\n",
    "        query = query_text,\n",
    "        experimental = {\n",
    "            \"QueryEmbedding\": query_embedding\n",
    "        },\n",
    "        columns=[\n",
    "            \"ENRICHED_CHUNK\",\n",
    "            \"PDF_FILE_NAME\",\n",
    "            \"IMAGE_FILE_NAME\",\n",
    "            \"ORIGINAL_FILE_NAME\",\n",
    "            \"PAGE_NUMBER\"\n",
    "        ],\n",
    "        limit=50\n",
    "    )\n",
    "    return resp.to_json()\n",
    "\n",
    "\n",
    "def create_temp_image_from_text(text: str) -> tuple[str, str]:\n",
    "    query_hash = hashlib.md5(text.strip().lower().encode()).hexdigest()\n",
    "    image_filename = f\"{query_hash}.png\"\n",
    "\n",
    "    temp_file = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False)\n",
    "    file_path = temp_file.name\n",
    "    temp_file.close()\n",
    "\n",
    "    image = Image.new(\"RGB\", (1000, 200), \"white\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default()\n",
    "    draw.text((10, 10), text, fill=\"black\", font=font)\n",
    "    image.save(file_path)\n",
    "\n",
    "\n",
    "    return file_path, image_filename\n",
    "\n",
    "\n",
    "def extract_cited_docs_and_pages(text_answer_str):\n",
    "    cited = {}\n",
    "    matches = re.findall(r\"CITED SOURCES:\\s*(.+)\", text_answer_str, re.IGNORECASE)\n",
    "    for match in matches:\n",
    "        doc_page_pairs = re.findall(r\"([a-zA-Z0-9._ -]+?)\\s*-\\s*page\\s*(\\d+)\", match)\n",
    "        for doc, page in doc_page_pairs:\n",
    "            doc = doc.strip().lower()\n",
    "            page = page.strip()\n",
    "            cited.setdefault(doc, set()).add(page)\n",
    "    return cited\n",
    "\n",
    "def extract_page_number(image_file_name: str) -> str:\n",
    "    match = re.search(r'_page_(\\d+)\\.png$', image_file_name)\n",
    "    return match.group(1) if match else \"N/A\"\n",
    "\n",
    "\n",
    "def file_exists_in_stage(session, stage_name: str, file_path: str) -> bool:\n",
    "    result = session.sql(f\"list @{stage_name}/{file_path}\").collect()\n",
    "    return bool(result)\n",
    "\n",
    "\n",
    "def fuzzy_match(a, b, threshold=0.6):\n",
    "    return SequenceMatcher(None, a.lower(), b.lower()).ratio() >= threshold\n",
    "\n",
    "\n",
    "def upload_file_to_stage(session, local_path: str, stage_name: str, dest_file_name: str):\n",
    "    temp_dir = tempfile.gettempdir()\n",
    "    temp_named_path = os.path.join(temp_dir, dest_file_name)\n",
    "\n",
    "    os.makedirs(os.path.dirname(temp_named_path), exist_ok=True)\n",
    "    shutil.copyfile(local_path, temp_named_path)\n",
    "\n",
    "    try:\n",
    "        result = session.file.put(\n",
    "            temp_named_path,\n",
    "            f\"@{stage_name}/queries\",\n",
    "            overwrite=True,\n",
    "            auto_compress=False\n",
    "        )\n",
    "        \n",
    "    finally:\n",
    "        os.remove(temp_named_path)\n",
    "\n",
    "\n",
    "def get_text_embedding_via_image(\n",
    "    session, \n",
    "    text: str, \n",
    "    stage_name=\"@utils.ai.stock_ikb_documents\"\n",
    "):\n",
    "    temp_path, image_filename = create_temp_image_from_text(text)\n",
    "    stage_subpath = f\"queries/{image_filename}\"\n",
    "\n",
    "    try:\n",
    "        if not file_exists_in_stage(session, stage_name.lstrip(\"@\"), stage_subpath):\n",
    "            upload_file_to_stage(session, temp_path, stage_name.lstrip(\"@\"), stage_subpath)\n",
    "            \n",
    "        query = f\"\"\"\n",
    "            select \n",
    "                snowflake.cortex.embed_image_1024(\n",
    "                    'voyage-multimodal-3', \n",
    "                    '{stage_name}',\n",
    "                    '{stage_subpath.lstrip('/')}'\n",
    "                )\n",
    "        \"\"\"\n",
    "        embedding = session.sql(query).collect()[0][0]\n",
    "    finally:\n",
    "        os.remove(temp_path)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def resolve_async_job(job):\n",
    "    try:\n",
    "        row = job.result()[0].asDict()\n",
    "        return {\n",
    "            \"RESULT\": row[\"RESULT\"],\n",
    "            \"ORIGINAL_FILE_NAME\": row[\"ORIGINAL_FILE_NAME\"],\n",
    "            \"IMAGE_FILE_NAME\": row[\"IMAGE_FILE_NAME\"],\n",
    "            \"PRESIGNED_URL\": row.get(\"PRESIGNED_URL\", \"#\")\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"RESULT\": f\"Error: {e}\",\n",
    "            \"ORIGINAL_FILE_NAME\": None,\n",
    "            \"IMAGE_FILE_NAME\": None,\n",
    "            \"PRESIGNED_URL\": \"#\"\n",
    "        }\n",
    "\n",
    "\n",
    "def rephrase_for_search(question):\n",
    "    return question.strip().lower()\n",
    "\n",
    "\n",
    "def filter_by_confidence(responses, threshold=0.5):\n",
    "    filtered = []\n",
    "    for item in responses:\n",
    "        match = re.search(r\"CONFIDENCE:\\s*([0-9.]+)\", item[\"RESULT\"], re.IGNORECASE)\n",
    "        score = float(match.group(1)) if match else 0.0\n",
    "        if score >= threshold:\n",
    "            filtered.append(item)\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def sql_escape(value):\n",
    "    return str(value).replace(\"'\", \"''\") if value is not None else \"\"\n",
    "\n",
    "\n",
    "def run_model(model_name, llm_prompt, session, temperature, max_tokens, top_p, guardrails, stream):\n",
    "    return complete(\n",
    "        model=model_name,\n",
    "        prompt=[{\"role\": \"user\", \"content\": llm_prompt}],\n",
    "        session=session,\n",
    "        options=CompleteOptions(\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=top_p,\n",
    "            guardrails=guardrails\n",
    "        ),\n",
    "        stream=stream\n",
    "    )\n",
    "\n",
    "\n",
    "def ai_complete_on_text(session, question, retrieved_chunks):\n",
    "    seen = set()\n",
    "    enriched_context_blocks = []\n",
    "\n",
    "    for chunk in retrieved_chunks:\n",
    "        enriched_chunk = chunk[\"ENRICHED_CHUNK\"]\n",
    "        original_file = chunk.get(\"ORIGINAL_FILE_NAME\")\n",
    "        image_file = chunk.get(\"IMAGE_FILE_NAME\")\n",
    "\n",
    "        if not image_file or not original_file:\n",
    "            continue\n",
    "\n",
    "        key = (original_file, image_file, enriched_chunk)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "\n",
    "        # Generate presigned URL\n",
    "        presigned_url = session.sql(\n",
    "            f\"SELECT GET_PRESIGNED_URL(@utils.ai.stock_ikb_documents, '{sql_escape(image_file)}')\"\n",
    "        ).collect()[0][0]\n",
    "\n",
    "        # Format for the model\n",
    "        block = dedent(f\"\"\"\n",
    "        ---\n",
    "        📄 **Source**: [{original_file}]({presigned_url})\n",
    "        📜 **Extracted Content**:\n",
    "        {enriched_chunk}\n",
    "        \"\"\").strip()\n",
    "\n",
    "        enriched_context_blocks.append(block)\n",
    "\n",
    "    if not enriched_context_blocks:\n",
    "        return {\"result\": \"No usable context.\", \"metadata\": {}}\n",
    "\n",
    "    full_context = \"\\n\\n\".join(enriched_context_blocks)\n",
    "\n",
    "    prompt = dedent(f\"\"\"\n",
    "    You are a document reasoning assistant helping users answer precise technical \n",
    "    questions about door hardware products, based on structured document \n",
    "    text (e.g., catalogs, price lists, manuals).\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ## Your Task:\n",
    "    Answer the user's question using only the provided context. \n",
    "    Each context block includes extracted text from one document page.\n",
    "    \n",
    "    ---\n",
    "    ## Precision Requirements:\n",
    "    - Only use rows or facts that match **all explicit constraints** \n",
    "        in the question (e.g., function, design, series, finish, cylinder type, etc.).\n",
    "    - Do not include unrelated variants \n",
    "        (e.g., do not include \"passage\" if the question is about \"cylinders\").\n",
    "    - If a match is ambiguous or unsupported, say so rather than guessing.\n",
    "    - Avoid over-including part numbers or configurations that don't clearly satisfy the question.\n",
    "    - If conflicting information exists, use the context to determine which source is more up-to-date.\n",
    "    - Cited sources MUST include hyperlinks to the original document using the presigned_url\n",
    "    \n",
    "    ---\n",
    "    ## Response Format:\n",
    "    - Start with a **DIRECT ANSWER** — a clear response to the question (price, part number, YES/NO, etc.).\n",
    "    - Then include:\n",
    "      - `CONFIDENCE:` (a float from 0.0 to 1.0)\n",
    "      - `JUSTIFICATION:` why this answer is supported by the data\n",
    "      - `CITED SOURCES:` in the form [`Document Name - page X`](presigned_url)\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ## Question:\n",
    "    {question.strip()}\n",
    "    \n",
    "    ## Context:\n",
    "    {full_context}\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    ## Output Format:\n",
    "    DIRECT ANSWER:  \n",
    "    CONFIDENCE:  \n",
    "    JUSTIFICATION:  \n",
    "    CITED SOURCES:\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "    result = complete(\n",
    "        model=\"claude-3-7-sonnet\",\n",
    "        prompt=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        session=session,\n",
    "        options=CompleteOptions(\n",
    "            temperature=0,\n",
    "            max_tokens=2048,\n",
    "            top_p=1,\n",
    "            guardrails=False\n",
    "        ),\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"result\": \"\".join(result),\n",
    "        \"metadata\": {\n",
    "            \"source\": \"TEXT\",\n",
    "            \"num_chunks\": len(retrieved_chunks)\n",
    "        },\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "\n",
    "\n",
    "def ai_complete_on_image_async(session, question, item, text_answer):\n",
    "    image_file_name = item[\"IMAGE_FILE_NAME\"]\n",
    "    original_file_name = item.get(\"ORIGINAL_FILE_NAME\", \"\")\n",
    "    page_number = item.get(\"PAGE_NUMBER\", \"\")\n",
    "\n",
    "    # Escape for SQL\n",
    "    image_file_escaped = sql_escape(image_file_name)\n",
    "    original_file_escaped = sql_escape(original_file_name)\n",
    "    document_metadata_escaped = sql_escape(original_file_name)\n",
    "    page_metadata_escaped = sql_escape(str(page_number))\n",
    "    answer_snippet_escaped = sql_escape(text_answer[\"result\"][:2000])  # trim long strings for prompt\n",
    "\n",
    "    prompt = dedent(f\"\"\"\n",
    "    You are validating a textual answer using the actual document page image.\n",
    "\n",
    "    ---\n",
    "    **User Question**: {question.strip()}\n",
    "\n",
    "    ---\n",
    "    **Answer to Critique**:\n",
    "    {text_answer[\"result\"]}\n",
    "\n",
    "    ---\n",
    "    **Image Source**: Document: `{original_file_name}`, Page: {page_number}\n",
    "\n",
    "    Your job is to check if the provided answer is correct and properly grounded in the image.\n",
    "    - Identify any factual errors, missing context, or overclaims.\n",
    "    - Be strict: only endorse what is clearly present in the image.\n",
    "    - If the image is not useful for critiquing the answer then say so.\n",
    "    - If the response is incorrect, provide the correct answer.\n",
    "    \n",
    "    Output format:\n",
    "    CRITIQUE_RESULT:  \n",
    "    JUSTIFICATION:  \n",
    "    CITED SOURCES:\n",
    "    \"\"\")\n",
    "\n",
    "    prompt_escaped = prompt.replace(\"'\", \"\\\\'\")\n",
    "\n",
    "    df = session.sql(f\"\"\"\n",
    "        select \n",
    "            '{original_file_escaped}' as original_file_name,\n",
    "            '{image_file_escaped}' as image_file_name,\n",
    "            '{document_metadata_escaped}' as document_metadata,\n",
    "            '{page_metadata_escaped}' as page_metadata,\n",
    "            get_presigned_url('@utils.ai.stock_ikb_documents', '{image_file_escaped}') as presigned_url,\n",
    "            ai_complete(\n",
    "                'claude-3-7-sonnet',\n",
    "                '{prompt_escaped}',\n",
    "                to_file('@utils.ai.stock_ikb_documents', '{image_file_escaped}'),\n",
    "                object_construct('temperature', 0.2, 'top_p', 1.0, 'max_tokens', 2048, 'guardrails', FALSE)\n",
    "            ) as result\n",
    "    \"\"\")\n",
    "    return df.collect_nowait()\n",
    "\n",
    "\n",
    "def synthesise_all_answers(session, question, text_answer_dict, image_answer_dicts):\n",
    "    text_result = text_answer_dict[\"result\"]\n",
    "    text_meta = text_answer_dict.get(\"metadata\", {})\n",
    "\n",
    "    image_sections = []\n",
    "    for img in image_answer_dicts:\n",
    "        presigned_link = img.get(\"PRESIGNED_URL\", \"#\")\n",
    "        section = dedent(f\"\"\"\n",
    "        --- \n",
    "        📄 **Source**: [{img[\"ORIGINAL_FILE_NAME\"]}]({presigned_link})\n",
    "        🖼️ Image File: `{img[\"IMAGE_FILE_NAME\"]}`\n",
    "\n",
    "        📘 Page Metadata:\n",
    "        {img.get(\"PAGE_METADATA\", \"N/A\")}\n",
    "\n",
    "        📚 Document Metadata:\n",
    "        {img.get(\"DOCUMENT_METADATA\", \"N/A\")}\n",
    "\n",
    "        📌 Critique of Text Answer:\n",
    "        {img[\"RESULT\"]}\n",
    "        \"\"\")\n",
    "        image_sections.append(section.strip())\n",
    "\n",
    "    image_critique_block = \"\\n\\n\".join(image_sections)\n",
    "\n",
    "    prompt = dedent(f\"\"\"\\\n",
    "    You are refining a text-based answer using critiques from document image analysis.\n",
    "\n",
    "    ## User Question:\n",
    "    {question}\n",
    "\n",
    "    ## Original Text Answer:\n",
    "    {text_result}\n",
    "\n",
    "    ## Image-Based Critiques:\n",
    "    {image_critique_block}\n",
    "\n",
    "    ---\n",
    "    ## Final Synthesized Answer:\n",
    "    - Revise the original text answer if needed.\n",
    "    - Improve factual accuracy using the critiques.\n",
    "    - Remove anything unsupported.\n",
    "    - Clearly cite updated sources.\n",
    "    - Final answer should be **concise, accurate, and directly responsive** to the user's question.\n",
    "    - Rephrase the technical answer so it's clear and understandable to the user.\n",
    "    - Do **not** include system fields like CONFIDENCE or JUSTIFICATION.\n",
    "    - Instead, write the answer as if you were explaining it to a knowledgeable customer.\n",
    "    - At the end, include a **Cited Sources** section with **Markdown hyperlinks** using the provided list.\n",
    "\n",
    "    ## Final Output:\n",
    "    - ANSWER:\n",
    "    - CITED SOURCES: \n",
    "        - [<file_name> - page <number>](url)\n",
    "    \"\"\")\n",
    "\n",
    "    result = complete(\n",
    "        model=\"claude-3-7-sonnet\",\n",
    "        prompt=prompt,\n",
    "        session=session,\n",
    "        options=CompleteOptions(\n",
    "            temperature=0.2, max_tokens=2048, top_p=1.0, guardrails=False\n",
    "        ),\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return \"\".join(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3359b5-43db-4b12-994a-c538445dfcdf",
   "metadata": {
    "collapsed": false,
    "name": "MD_streamlit_interface"
   },
   "source": [
    "## 📘 Streamlit App: Seclock Multimodal Q\\&A Workflow\n",
    "\n",
    "This app provides an interactive interface for querying technical door hardware documents using a **multimodal pipeline**—combining semantic search, text comprehension, image-based validation, and answer synthesis.\n",
    "\n",
    "### 🔢 **Workflow Overview**\n",
    "\n",
    "The pipeline consists of **7 sequential steps**, shown with real-time status updates in the UI:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Document Search (Cortex Semantic Search)**\n",
    "\n",
    "* The user enters a question via `st.chat_input()`.\n",
    "* The question is normalized using `rephrase_for_search()`.\n",
    "* `query_search_service()` performs an **embedding + keyword** search using the Cortex Search Service.\n",
    "* Returns up to 50 enriched document chunks with metadata, image filenames, and associated PDF references.\n",
    "* If no chunks are found, the assistant replies with a fallback message.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Answer Generation from Text Chunks**\n",
    "\n",
    "* `ai_complete_on_text()` receives the retrieved chunks and builds a prompt with:\n",
    "\n",
    "  * **Clickable presigned URLs**\n",
    "  * Clean markdown formatting\n",
    "  * Strong precision constraints to avoid hallucinations\n",
    "* The model (`claude-3-7-sonnet`) returns:\n",
    "\n",
    "  * A **direct answer**\n",
    "  * A **confidence score**\n",
    "  * A **justification**\n",
    "  * **CITED SOURCES** with Markdown links\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Image Deduplication**\n",
    "\n",
    "* To reduce cost and noise, `(PDF_FILE_NAME, IMAGE_FILE_NAME)` pairs are deduplicated.\n",
    "* This ensures each page is only submitted once for image-based validation.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Extract Cited Sources & Pages**\n",
    "\n",
    "* The model's output from Step 2 is parsed using `extract_cited_docs_and_pages()` to identify only the **relevant documents and pages** to check against image data.\n",
    "* Uses regex to extract all `Document - page X` citations for focused validation.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Filter Images to Cited Pages**\n",
    "\n",
    "* The deduplicated images are **filtered** to those matching the cited documents and pages.\n",
    "* Matching is done via fuzzy string matching and page number extraction.\n",
    "* Each matched page is then submitted to Cortex with `ai_complete_on_image_async()` for image critique.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Run Image-Based Validation (Async)**\n",
    "\n",
    "* Cortex jobs are resolved using `resolve_async_job()` and visual progress is displayed.\n",
    "* Errors are handled gracefully, and failed results are tagged with placeholders.\n",
    "* The results include `RESULT`, `PRESIGNED_URL`, and other metadata fields.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Final Answer Synthesis**\n",
    "\n",
    "* All validated image responses are passed to `synthesise_all_answers()` along with the original text answer.\n",
    "* The synthesis prompt:\n",
    "\n",
    "  * Merges, reconciles, and improves factual accuracy.\n",
    "  * Rephrases the result clearly for human readers.\n",
    "  * **Cites each document+page with a working hyperlink**.\n",
    "* The result is then displayed to the user in the chat.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3ad13-7e91-407b-9d5f-c2eb38822aa4",
   "metadata": {
    "language": "python",
    "name": "PY_streamlit_interface"
   },
   "outputs": [],
   "source": [
    "user_question = st.chat_input(\"Ask a question about door hardware documents...\")\n",
    "\n",
    "root = Root(sp_session)\n",
    "search_service = (root\n",
    "  .databases[\"UTILS\"]\n",
    "  .schemas[\"AI\"]\n",
    "  .cortex_search_services[\"DOCS_SEARCH_SERVICE\"]\n",
    ")\n",
    "\n",
    "if user_question:\n",
    "    overall_start = time.time()\n",
    "    st.chat_message(\"user\").write(user_question)\n",
    "\n",
    "    steps = [\n",
    "        \"Search documents\",\n",
    "        \"Generate text answer\",\n",
    "        \"Deduplicate image chunks\",\n",
    "        \"Extract cited pages\",\n",
    "        \"Filter images to cited pages\",\n",
    "        \"Run image-based critique\",\n",
    "        \"Synthesize final answer\"\n",
    "    ]\n",
    "\n",
    "    with st.spinner(\"Thinking...\"):\n",
    "        # Init UI placeholders\n",
    "        status_step = st.empty()\n",
    "        status_stage = st.empty()\n",
    "        status_detail = st.empty()\n",
    "        status_progress = st.empty()\n",
    "        status_total_time = st.empty()\n",
    "\n",
    "        # --- Step 1: Search documents ---\n",
    "        step = 0\n",
    "        start = time.time()\n",
    "        status_step.markdown(f\"### 🔍 Step {step + 1} of {len(steps)}: {steps[step]}\")\n",
    "        status_stage.markdown(\"Searching document chunks using Cortex search...\")\n",
    "        search_query = rephrase_for_search(user_question)\n",
    "        raw_results = query_search_service(sp_session, search_service, search_query)\n",
    "        results = json.loads(raw_results)[\"results\"]\n",
    "        retrieved_chunks = results\n",
    "        status_detail.markdown(f\"Found `{len(retrieved_chunks)}` document chunks in `{time.time() - start:.2f}` seconds.\")\n",
    "\n",
    "        if not retrieved_chunks:\n",
    "            st.chat_message(\"assistant\").write(\"I couldn't find anything relevant in the documents.\")\n",
    "        else:\n",
    "            # --- Step 2: Text generation ---\n",
    "            step += 1\n",
    "            start = time.time()\n",
    "            status_step.markdown(f\"### 📝 Step {step + 1} of {len(steps)}: {steps[step]}\")\n",
    "            status_stage.markdown(\"Generating structured answer from retrieved text...\")\n",
    "            answer_text = ai_complete_on_text(sp_session, user_question, retrieved_chunks)\n",
    "            status_detail.markdown(f\"Answer generated in `{time.time() - start:.2f}` seconds.\")\n",
    "\n",
    "            # --- Step 3: Deduplicate images ---\n",
    "            step += 1\n",
    "            start = time.time()\n",
    "            status_step.markdown(f\"### 🧼 Step {step + 1} of {len(steps)}: {steps[step]}\")\n",
    "            status_stage.markdown(\"Removing duplicate images by document + page...\")\n",
    "            seen = set()\n",
    "            deduped_results = []\n",
    "            for item in results:\n",
    "                key = (item[\"PDF_FILE_NAME\"], item[\"IMAGE_FILE_NAME\"])\n",
    "                if key not in seen:\n",
    "                    seen.add(key)\n",
    "                    deduped_results.append(item)\n",
    "            status_detail.markdown(f\"Deduplicated to `{len(deduped_results)}` unique images in `{time.time() - start:.2f}` seconds.\")\n",
    "\n",
    "            # --- Step 4: Extract cited pages ---\n",
    "            step += 1\n",
    "            status_step.markdown(f\"### 📄 Step {step + 1} of {len(steps)}: {steps[step]}\")\n",
    "            status_stage.markdown(\"Parsing cited documents and pages from answer...\")\n",
    "            cited_docs_pages = extract_cited_docs_and_pages(answer_text[\"result\"])\n",
    "            status_detail.markdown(f\"Found `{sum(len(pgs) for pgs in cited_docs_pages.values())}` total cited pages.\")\n",
    "\n",
    "            # --- Step 5: Filter to cited pages ---\n",
    "            step += 1\n",
    "            start = time.time()\n",
    "            status_step.markdown(f\"### 🔎 Step {step + 1} of {len(steps)}: {steps[step]}\")\n",
    "            status_stage.markdown(\"Matching deduplicated images to cited documents and pages...\")\n",
    "\n",
    "            jobs = []\n",
    "            matched_files = []\n",
    "            skipped_files = []\n",
    "\n",
    "            for item in deduped_results:\n",
    "                original_file = item.get(\"ORIGINAL_FILE_NAME\", \"\")\n",
    "                base_name = os.path.splitext(original_file)[0].lower()\n",
    "                image_file = item.get(\"IMAGE_FILE_NAME\", \"\")\n",
    "                page_number = extract_page_number(image_file)\n",
    "\n",
    "                matched = any(\n",
    "                    cited_doc in base_name and page_number in cited_docs_pages[cited_doc]\n",
    "                    for cited_doc in cited_docs_pages\n",
    "                )\n",
    "\n",
    "                if matched:\n",
    "                    matched_files.append(f\"{base_name} - page {page_number}\")\n",
    "                    job = ai_complete_on_image_async(sp_session, user_question, item, answer_text)\n",
    "                    if job:\n",
    "                        jobs.append((item, job))\n",
    "                else:\n",
    "                    skipped_files.append(f\"{base_name} - page {page_number}\")\n",
    "\n",
    "            status_detail.markdown(f\"Matched `{len(matched_files)}` / `{len(deduped_results)}` images in `{time.time() - start:.2f}` seconds.\")\n",
    "\n",
    "            # --- Step 6: Run image-based critique ---\n",
    "            step += 1\n",
    "            start = time.time()\n",
    "            status_step.markdown(f\"### 🧠 Step {step + 1} of {len(steps)}: {steps[step]}\")\n",
    "            status_stage.markdown(\"Submitting matched images to Cortex for validation...\")\n",
    "\n",
    "            image_answers = []\n",
    "            total_jobs = len(jobs)\n",
    "            progress_bar = status_progress.progress(0.0, text=\"Processing image critiques...\")\n",
    "\n",
    "            for i, (item, job) in enumerate(jobs, start=1):\n",
    "                try:\n",
    "                    result = resolve_async_job(job)\n",
    "                    result[\"PAGE_NUMBER\"] = extract_page_number(item[\"IMAGE_FILE_NAME\"])\n",
    "                    image_answers.append(result)\n",
    "                except Exception as e:\n",
    "                    image_answers.append({\n",
    "                        \"RESULT\": f\"Error: {e}\",\n",
    "                        \"ORIGINAL_FILE_NAME\": item.get(\"ORIGINAL_FILE_NAME\"),\n",
    "                        \"IMAGE_FILE_NAME\": item.get(\"IMAGE_FILE_NAME\"),\n",
    "                        \"PAGE_NUMBER\": extract_page_number(item.get(\"IMAGE_FILE_NAME\", \"\")),\n",
    "                        \"PRESIGNED_URL\": \"#\"\n",
    "                    })\n",
    "                progress_bar.progress(i / total_jobs, text=f\"Processing image critiques... ({i}/{total_jobs})\")\n",
    "\n",
    "            status_detail.markdown(f\"Image critique completed in `{time.time() - start:.2f}` seconds.\")\n",
    "\n",
    "            # --- Step 7: Synthesize answer ---\n",
    "            step += 1\n",
    "            start = time.time()\n",
    "            status_step.markdown(f\"### 🧪 Step {step + 1} of {len(steps)}: {steps[step]}\")\n",
    "            status_stage.markdown(\"Synthesizing text + image answers into a final response...\")\n",
    "\n",
    "            image_answers_filtered = filter_by_confidence(image_answers)\n",
    "            final_answer = synthesise_all_answers(\n",
    "                sp_session,\n",
    "                user_question,\n",
    "                answer_text,\n",
    "                image_answers_filtered\n",
    "            )\n",
    "            status_detail.markdown(f\"Final synthesis completed in `{time.time() - start:.2f}` seconds.\")\n",
    "\n",
    "            # --- Display ---\n",
    "            total_time = time.time() - overall_start\n",
    "            status_total_time.markdown(f\"⏱️ **Total time taken**: `{total_time:.2f}` seconds\")\n",
    "            st.chat_message(\"assistant\").markdown(f\"**Final Answer:**\\n{final_answer}\")\n",
    "\n",
    "            with st.expander(\"🔍 Debug - Raw Text Answer\"):\n",
    "                with st.chat_message(\"assistant\"):\n",
    "                    if results:\n",
    "                        st.write(\"📚 **Documents included:**\")\n",
    "                        for doc in sorted(set(item[\"ORIGINAL_FILE_NAME\"] for item in results)):\n",
    "                            st.write(f\"• `{doc}`\")\n",
    "                    st.markdown(\"---\")\n",
    "                    st.markdown(\"📝 **Text-Based Answer:**\")\n",
    "                    st.markdown(answer_text[\"result\"])\n",
    "\n",
    "            with st.expander(\"🔍 Debug - Raw Image Answers\"):\n",
    "                for i, ans in enumerate(image_answers, start=1):\n",
    "                    with st.chat_message(\"assistant\"):\n",
    "                        st.markdown(f\"**Image Answer {i}:**\")\n",
    "                        st.write(f\"📄 **Document**: `{ans['ORIGINAL_FILE_NAME']}`\")\n",
    "                        st.write(f\"🖼️ **Image File**: `{ans['IMAGE_FILE_NAME']}`\")\n",
    "                        st.markdown(ans[\"RESULT\"])\n",
    "\n",
    "\n",
    "            with st.expander(\"Prompt\"):\n",
    "                st.write(answer_text[\"prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f582e5-bfba-4b2c-9c5d-bace5dcd897d",
   "metadata": {
    "collapsed": false,
    "name": "MD_groundtruth_results"
   },
   "source": [
    "## Groundtruth Questions\n",
    "\n",
    "1. What is the part number for a 10 line Y design cylinder?\n",
    "\n",
    "    **🔴 Seclock Answer**: 10-0613 left, 10-0614 right\n",
    "\n",
    "    **🤖 Solution Answer**:\n",
    "\n",
    "    > The part number for a 10 line Y design cylinder is 10-0613 (left-handed) or 10-0614 (right-handed). These are part of the Coastal Series and include both the cylinder and emergency release components.\n",
    "\n",
    "---\n",
    "2. Is chexit available on a 9947-F?\n",
    "\n",
    "    **🔴 Seclock Answer**: No, dogging is not an option on fire rated devices\n",
    "\n",
    "    **🤖 Solution Answer**:\n",
    "\n",
    "    > Yes, Chexit is available on a 9947-F device.\n",
    "    > \n",
    "    > The documentation confirms that Chexit (CX) is compatible with the 9947/9947-F model. This is shown in the minimum door opening sizes table for CX devices, which specifically lists \"CX9847/9847-F/9947/9947-F\" as compatible devices. Additionally, the Von Duprin price book states that \"CHEXIT - Available on all 98/99 Series devices,\" which includes the 9947-F model.\n",
    "    > \n",
    "    > When ordering, you would use the prefix \"CXA\" before the device model number to specify the Chexit option.\n",
    "\n",
    "---\n",
    "3. What is the case quantity and weight of a 281 Series O function?\n",
    "\n",
    "    **🔴 Seclock Answer**: Average weight is 24lbs, case quantity is 2\n",
    "\n",
    "    **🤖 Solution Answer**:\n",
    "    > The 281 Series O function has a case quantity of 2 and weighs 24 pounds per case.\n",
    "    > \n",
    "    > This information comes from the Sargent 2025 Price Book's Freight Weight Chart section, which specifically lists these specifications for the 281 Series.\n",
    "\n",
    "---\n",
    "4. On a Schlage ND, is vandlgard available in double cylinder functions?\n",
    "\n",
    "    **🔴 Seclock Answer**: Yes, functions 72 with XN12-003, 93 and 98\n",
    "\n",
    "    **🤖 Solution Answer**:\n",
    "    > Yes, Vandlgard is available in double cylinder functions on the Schlage ND Series. Specifically, it's available in these models:\n",
    "    > \n",
    "    > ND72 with XN12-003 (F80): Vandlgard communicating lock\n",
    "    > ND93 (F88): Vandlgard vestibule lock\n",
    "    > ND98 (F110): Vandlgard classroom security lock with 180-degree lockdown\n",
    "    > The Vandlgard feature allows the outside lever to rotate freely when locked, which helps prevent damage from vandalism by limiting the force that can be applied to the internal lock components.\n",
    "\n",
    "---\n",
    "5. What’s the part number for an L9460 armor front?\n",
    "\n",
    "    **🔴 Seclock Answer**: 09-665, you must also specify the finish\n",
    "\n",
    "    **🤖 Solution Answer**:\n",
    "\n",
    "    > The part number for an L9460 armor front is 09-665. This part is specifically designed for deadbolt configurations including the L9460 model.\n",
    "\n",
    "---\n",
    "6. What is the prefix for rail monitoring on a Sargent 80 device?\n",
    "\n",
    "    **🔴 Seclock Answer**: 55\n",
    "\n",
    "    **🤖 Solution Answer**:\n",
    "    > The prefix for rail monitoring on a Sargent 80 device is \"55-\". This prefix designates the Request-to-Exit option, which provides push rail monitoring functionality for various applications on Sargent's 80 Series exit devices. When ordering, you would include this prefix before the model number (for example: 55-8913F x ETMA x 32D x 36\").\n",
    "\n",
    "---\n",
    "7. What’s the list price for a Sargent 13-0404 cylinder plug size 44?\n",
    "\n",
    "    **🔴 Seclock Answer**: $44.44\n",
    "\n",
    "    **🤖 Solution Answer**: \n",
    "    \n",
    "    > The list price for a Sargent 13-0404 cylinder plug size 44 is $44.44.\n",
    "    \n",
    "---\n",
    "8. What finishes do Sargent mortise cylinder barrels coming in?\n",
    "    \n",
    "    **🔴 Seclock Answer**: US4, US15, and BSP\n",
    "\n",
    "    **🤖 Solution Answer**:\n",
    "\n",
    "    > Sargent mortise cylinder barrels come in three finishes: US4 (satin brass), US15 (satin nickel), and BSP (black suede powder coat).\n",
    "    > \n",
    "    > It's important to note that while the overall mortise cylinders are available in many different finishes (including US3, US9, US10, US10B, US10BE, US10BL, US20D, US32, US32D, BSP, WSP), the cylinder plugs/barrels specifically are only offered in these three finish options.\n",
    "\n",
    "---\n",
    "9. In ALX, what are the Less FSIC cylinder options?\n",
    "    \n",
    "    **🔴 Seclock Answer**: J-CO6 Less FSIC, made to fit Corbin 8000, J-CO7 Less FSIC, made to fit Corbin 8000-7, J-SAR Less FSIC, made to fit Sargent 6300\n",
    "\n",
    "    **🤖 Solution Answer**:\n",
    "    > In the ALX Series, the Less FSIC (Full Size Interchangeable Core) cylinder options are:\n",
    "    > \n",
    "    > * J-SAR: Less cylinder, made to fit Sargent 6300 6-pin FSIC\n",
    "    > * J-CO6: Less cylinder, made to fit Corbin 8000 6-pin FSIC\n",
    "    > * J-CO7: Less cylinder, made to fit Corbin 8000-7 7-pin FSIC\n",
    "    > \n",
    "    > These options allow you to use your existing FSIC cylinders with ALX Series locks, providing flexibility when integrating with existing key systems.\n",
    "\n",
    "---\n",
    "10. Is Schlage 7800 KE3/KE4 available with double cylinders?\n",
    "    \n",
    "    **🔴 Seclock Answer**: No, designed for exposed barrels only\n",
    "\n",
    "    **🤖 Solution Answer**:\n",
    "    \n",
    "    > No, the Schlage 7800 KE3/KE4 is not available with double cylinders. The product catalog specifically states that the KE3/KE4 escutcheon design cannot be used with double cylinder functions, which is an important limitation to note when considering this particular lock option."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "christopher.marland@aimpointdigital.com",
   "authorId": "854535573994",
   "authorName": "CMARLAND_AIMPOINT",
   "lastEditTime": 1751040083263,
   "notebookId": "epymhcytdfsudo5veh2t",
   "sessionId": "c3a0c626-cb5d-49e4-8e9c-787965ca12eb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
